{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from args import *\n",
    "from train_test_functions import *\n",
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(cuda=torch.cuda.is_available(), graph_name='ENZYMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA True\n"
     ]
    }
   ],
   "source": [
    "args.epochs = 2000\n",
    "args.batch_size = 128\n",
    "args.reco_importance = 0.1\n",
    "args.loss = nn.BCELoss()\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.cuda)\n",
    "print('CUDA', args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph dataset: ENZYMES\n",
      "Loaded\n",
      "total graph num: 600, training set: 540\n",
      "max number node: 125\n",
      "max/min number edge: 149; 1\n",
      "max previous node: 25\n"
     ]
    }
   ],
   "source": [
    "graphs = graph_load_batch(data_directory=args.data_directory, name=args.graph_name)\n",
    "\n",
    "dataloaders_train, dataloaders_test = create_loaders(graphs, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number: 0\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.364, train kl loss: 0.012, classifier loss: 9.021\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.231, train kl loss: 0.019, classifier loss: 8.995\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.162, train kl loss: 0.031, classifier loss: 8.965\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.135, train kl loss: 0.039, classifier loss: 8.974\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.133, train kl loss: 0.042, classifier loss: 8.955\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.130, train kl loss: 0.039, classifier loss: 8.939\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.124, train kl loss: 0.035, classifier loss: 8.911\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.121, train kl loss: 0.032, classifier loss: 8.906\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.122, train kl loss: 0.030, classifier loss: 8.863\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.119, train kl loss: 0.029, classifier loss: 8.796\n",
      "Fold number: 1\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.357, train kl loss: 0.017, classifier loss: 9.007\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.221, train kl loss: 0.026, classifier loss: 9.063\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.167, train kl loss: 0.039, classifier loss: 8.998\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.133, train kl loss: 0.049, classifier loss: 8.954\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.123, train kl loss: 0.054, classifier loss: 8.942\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.116, train kl loss: 0.054, classifier loss: 8.910\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.114, train kl loss: 0.052, classifier loss: 8.868\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.114, train kl loss: 0.047, classifier loss: 8.847\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.116, train kl loss: 0.042, classifier loss: 8.823\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.112, train kl loss: 0.039, classifier loss: 8.777\n",
      "Fold number: 2\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.374, train kl loss: 0.015, classifier loss: 9.018\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.239, train kl loss: 0.026, classifier loss: 8.987\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.173, train kl loss: 0.040, classifier loss: 8.960\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.139, train kl loss: 0.048, classifier loss: 8.923\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.123, train kl loss: 0.050, classifier loss: 8.882\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.120, train kl loss: 0.046, classifier loss: 8.826\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.113, train kl loss: 0.042, classifier loss: 8.741\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.113, train kl loss: 0.038, classifier loss: 8.790\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.114, train kl loss: 0.036, classifier loss: 8.756\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.112, train kl loss: 0.035, classifier loss: 8.745\n",
      "Fold number: 3\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.356, train kl loss: 0.016, classifier loss: 9.013\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.239, train kl loss: 0.024, classifier loss: 8.960\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.177, train kl loss: 0.035, classifier loss: 8.938\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.145, train kl loss: 0.043, classifier loss: 8.941\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.133, train kl loss: 0.046, classifier loss: 8.892\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.125, train kl loss: 0.047, classifier loss: 8.858\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.113, train kl loss: 0.047, classifier loss: 8.846\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.115, train kl loss: 0.045, classifier loss: 8.827\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.112, train kl loss: 0.042, classifier loss: 8.795\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.117, train kl loss: 0.039, classifier loss: 8.774\n",
      "Fold number: 4\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.393, train kl loss: 0.013, classifier loss: 9.068\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.278, train kl loss: 0.020, classifier loss: 9.083\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.214, train kl loss: 0.027, classifier loss: 8.994\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.169, train kl loss: 0.036, classifier loss: 8.927\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.139, train kl loss: 0.044, classifier loss: 8.919\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.136, train kl loss: 0.048, classifier loss: 8.909\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.116, train kl loss: 0.048, classifier loss: 8.880\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.111, train kl loss: 0.045, classifier loss: 8.823\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.113, train kl loss: 0.042, classifier loss: 8.829\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.115, train kl loss: 0.037, classifier loss: 8.653\n",
      "Fold number: 5\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.390, train kl loss: 0.013, classifier loss: 8.987\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.254, train kl loss: 0.021, classifier loss: 8.959\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.172, train kl loss: 0.032, classifier loss: 8.938\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.148, train kl loss: 0.044, classifier loss: 8.913\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.124, train kl loss: 0.052, classifier loss: 8.877\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.116, train kl loss: 0.053, classifier loss: 8.843\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.120, train kl loss: 0.050, classifier loss: 8.831\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.120, train kl loss: 0.045, classifier loss: 8.788\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.117, train kl loss: 0.039, classifier loss: 8.715\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.113, train kl loss: 0.037, classifier loss: 8.674\n",
      "Fold number: 6\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.457, train kl loss: 0.012, classifier loss: 9.012\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.302, train kl loss: 0.020, classifier loss: 8.981\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.211, train kl loss: 0.032, classifier loss: 8.936\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.159, train kl loss: 0.043, classifier loss: 8.931\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.144, train kl loss: 0.051, classifier loss: 8.901\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.133, train kl loss: 0.055, classifier loss: 8.889\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.124, train kl loss: 0.053, classifier loss: 8.850\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.120, train kl loss: 0.049, classifier loss: 8.842\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.112, train kl loss: 0.044, classifier loss: 8.804\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.117, train kl loss: 0.040, classifier loss: 8.765\n",
      "Fold number: 7\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.311, train kl loss: 0.020, classifier loss: 9.122\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.217, train kl loss: 0.024, classifier loss: 8.961\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.165, train kl loss: 0.029, classifier loss: 8.946\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.131, train kl loss: 0.034, classifier loss: 8.955\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.116, train kl loss: 0.038, classifier loss: 8.925\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.111, train kl loss: 0.040, classifier loss: 8.925\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.102, train kl loss: 0.039, classifier loss: 8.895\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.111, train kl loss: 0.038, classifier loss: 8.896\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.107, train kl loss: 0.035, classifier loss: 8.868\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.100, train kl loss: 0.033, classifier loss: 8.859\n",
      "Fold number: 8\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.371, train kl loss: 0.014, classifier loss: 9.069\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.235, train kl loss: 0.021, classifier loss: 8.964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.167, train kl loss: 0.030, classifier loss: 8.956\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.141, train kl loss: 0.036, classifier loss: 8.933\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.126, train kl loss: 0.040, classifier loss: 8.909\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.125, train kl loss: 0.040, classifier loss: 8.900\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.121, train kl loss: 0.038, classifier loss: 8.878\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.114, train kl loss: 0.036, classifier loss: 8.858\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.119, train kl loss: 0.032, classifier loss: 8.830\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.117, train kl loss: 0.029, classifier loss: 8.788\n",
      "Fold number: 9\n",
      "Dataset: ENZYMES, Epoch: 1/10, train bce loss: 0.302, train kl loss: 0.024, classifier loss: 8.982\n",
      "Dataset: ENZYMES, Epoch: 2/10, train bce loss: 0.190, train kl loss: 0.035, classifier loss: 9.090\n",
      "Dataset: ENZYMES, Epoch: 3/10, train bce loss: 0.151, train kl loss: 0.045, classifier loss: 9.012\n",
      "Dataset: ENZYMES, Epoch: 4/10, train bce loss: 0.130, train kl loss: 0.050, classifier loss: 8.988\n",
      "Dataset: ENZYMES, Epoch: 5/10, train bce loss: 0.130, train kl loss: 0.051, classifier loss: 8.930\n",
      "Dataset: ENZYMES, Epoch: 6/10, train bce loss: 0.121, train kl loss: 0.048, classifier loss: 8.933\n",
      "Dataset: ENZYMES, Epoch: 7/10, train bce loss: 0.114, train kl loss: 0.043, classifier loss: 8.921\n",
      "Dataset: ENZYMES, Epoch: 8/10, train bce loss: 0.118, train kl loss: 0.039, classifier loss: 8.895\n",
      "Dataset: ENZYMES, Epoch: 9/10, train bce loss: 0.114, train kl loss: 0.034, classifier loss: 8.884\n",
      "Dataset: ENZYMES, Epoch: 10/10, train bce loss: 0.122, train kl loss: 0.031, classifier loss: 8.873\n",
      "[0.21666666666666667, 0.26666666666666666, 0.3, 0.26666666666666666, 0.26666666666666666, 0.26666666666666666, 0.23333333333333334, 0.2, 0.3, 0.26666666666666666]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "args.num_fold = None\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    print('Fold number: {:.0f}'.format(i+1))\n",
    "    args.num_fold = i\n",
    "\n",
    "    rnn_embedding = RecurrentEmbedding(input_size=args.node_dim, \n",
    "                                       embedding_size=args.embedding_size_rnn,\n",
    "                                       hidden_size=args.hidden_size_rnn, \n",
    "                                       num_layers=args.num_layers, \n",
    "                                       is_cuda=args.cuda)\n",
    "\n",
    "    var = VAR(h_size=args.hidden_size_rnn, \n",
    "              embedding_size=args.embedding_size_output,\n",
    "              y_size=args.node_dim, \n",
    "              is_cuda=args.cuda)\n",
    "\n",
    "    rnn_classifier = RecurrentClassifier(input_size=args.hidden_size_rnn, \n",
    "                                         embedding_size=args.embedding_size_rnn,\n",
    "                                         hidden_size=args.hidden_size_rnn, \n",
    "                                         num_layers=args.num_layers, \n",
    "                                         num_class=args.num_class,\n",
    "                                         is_cuda=args.cuda)\n",
    "\n",
    "    if args.cuda:\n",
    "        rnn_embedding = rnn_embedding.cuda()\n",
    "        var = var.cuda()\n",
    "        rnn_classifier = rnn_classifier.cuda()\n",
    "\n",
    "    learning_accuracy_test = classifier_train(args, \n",
    "                                              dataloaders_train[i], \n",
    "                                              dataloaders_test[i], \n",
    "                                              rnn_embedding, var, rnn_classifier)\n",
    "\n",
    "    accuracy_test, scores, predicted_labels, true_labels, vote = vote_test(args, \n",
    "                                                                           rnn_embedding, \n",
    "                                                                           var, \n",
    "                                                                           rnn_classifier,\n",
    "                                                                           dataloaders_test[i], \n",
    "                                                                           num_iteration=100)\n",
    "    \n",
    "    results[i] = {'rnn': rnn_embedding, 'output': var, 'classifier_1': rnn_classifier,\n",
    "                  'acc_test': accuracy_test, 'scores': scores}\n",
    "\n",
    "print([results[r]['acc_test'] for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2583333333333333 0.03095695936834451\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([results[r]['acc_test'] for r in results]), \n",
    "      np.std([results[r]['acc_test'] for r in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
